{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RKeS-b0n_xcA",
        "28RxDYo4TNKF",
        "uZFZFaCm25Pl",
        "HLHfz7A79ua0",
        "FGXawp4qguMp",
        "TUE8M8dYDhrS",
        "kk2D9IFLu-kS",
        "nTy7FF5Uq_HS",
        "Tzl__gO2rszR",
        "Sf94ZvnEDoNQ",
        "108cqSxAwCqH",
        "ySMFaLVas_Jq",
        "7C5oj-qztJCa",
        "lmvNzHt1HLGO",
        "ToCL-6EJ_H1v",
        "ZEr_mAzHASno",
        "dMcWiPIDCuBd",
        "QnaXXNNVHXEB",
        "4jprmmS4KpnG"
      ],
      "authorship_tag": "ABX9TyOPYaYrjL9Z5vCqxXaUO6mb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea8ef96525194d01b0f945b63c027509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_28dc5c105856418699b84a1d3ead4083",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4607880f82c847f2bf9387e357425547",
              "IPY_MODEL_af0ee04ec38347759ed18946845e984f"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "28dc5c105856418699b84a1d3ead4083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "4607880f82c847f2bf9387e357425547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7450412853a46a1b636a80dd71aeeaf",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 6000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7213f46d84042368d256c77bbf9231f"
          },
          "model_module_version": "1.5.0"
        },
        "af0ee04ec38347759ed18946845e984f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7f521120e6ed442b90700d5de1e2f6f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6000/6000 [01:54&lt;00:00, 52.49it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f84e1405a4604a7084fff8d3307aae27"
          },
          "model_module_version": "1.5.0"
        },
        "e7450412853a46a1b636a80dd71aeeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a7213f46d84042368d256c77bbf9231f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "7f521120e6ed442b90700d5de1e2f6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "f84e1405a4604a7084fff8d3307aae27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "09395ec5c4104369b7f7f84e988e444e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_81078f9f709f4e5297ee7a65a29351e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_939e3f059476476fa47a8d3fb8d3c715",
              "IPY_MODEL_913e0e4242ef4765aab6558b63730f4a"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "81078f9f709f4e5297ee7a65a29351e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "939e3f059476476fa47a8d3fb8d3c715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63f91a87b7844ce284a4018b2ba79bab",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 6000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_960e45b7c78646f48c718863fa2c77b0"
          },
          "model_module_version": "1.5.0"
        },
        "913e0e4242ef4765aab6558b63730f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc181147871442ca86433b5010ea3d6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6000/6000 [00:45&lt;00:00, 131.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32e45549d20e43d98a0c289f7c508ba6"
          },
          "model_module_version": "1.5.0"
        },
        "63f91a87b7844ce284a4018b2ba79bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "960e45b7c78646f48c718863fa2c77b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "cc181147871442ca86433b5010ea3d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "32e45549d20e43d98a0c289f7c508ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vall98/Vall98.github.io/blob/master/ShortVideoClipsMemorabilityPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWhhuLowvNMM"
      },
      "source": [
        "Name, Surname: Valentin Lebon\n",
        "\n",
        "Student ID: 19102232\n",
        "\n",
        "Programe: ECSAOO\n",
        "\n",
        "Module: 2019/2020 CA684 Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZB4p75z96K8"
      },
      "source": [
        "# 1. Get data and define useful functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKeS-b0n_xcA"
      },
      "source": [
        "### a. Import data in Google Collab\n",
        "\n",
        "This code mounts the user's Google Drive directory in this Ipython Notebook, and changes the working directory to Dev-set.\n",
        "\n",
        "It assumes that the Dev-set directory is available under the \"My Drive\" directory.\n",
        "\n",
        "Please also put the provided file \"my_saved_model.h5\" in a directory named \"models\" under the \"My Drive\" directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kkg7V8VTMDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d959b7-ce6f-441c-ff70-314f463a4040"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Dev-set\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28RxDYo4TNKF"
      },
      "source": [
        "### b. Get ground truth\n",
        "To be able to perform predictions over the ground truth, we need to retrieve it from the associate .csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9J9vD2ubVzt"
      },
      "source": [
        "ground_truth_file = 'Ground-truth/ground-truth.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT8CTqL3bY7E"
      },
      "source": [
        "(Optional) We are then able to examine the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLWS496QTM7O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "76126368-d803-4f07-d5e5-b83d796abb3a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "ground_truth = pd.read_csv(ground_truth_file)\n",
        "ground_truth.head()\n",
        "ground_truth.describe()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       short-term_memorability  nb_short-term_annotations  \\\n",
              "count              6000.000000                6000.000000   \n",
              "mean                  0.860243                  36.291500   \n",
              "std                   0.080655                   8.356285   \n",
              "min                   0.388000                  30.000000   \n",
              "25%                   0.811000                  33.000000   \n",
              "50%                   0.867000                  34.000000   \n",
              "75%                   0.923000                  34.000000   \n",
              "max                   0.989000                 100.000000   \n",
              "\n",
              "       long-term_memorability  nb_long-term_annotations  \n",
              "count             6000.000000               6000.000000  \n",
              "mean                 0.778942                 12.764667  \n",
              "std                  0.144692                  3.544815  \n",
              "min                  0.000000                  9.000000  \n",
              "25%                  0.700000                 10.000000  \n",
              "50%                  0.800000                 12.000000  \n",
              "75%                  0.900000                 14.000000  \n",
              "max                  1.000000                 40.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a74ff3f8-9f1c-45ac-bc18-006bb68be070\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>short-term_memorability</th>\n",
              "      <th>nb_short-term_annotations</th>\n",
              "      <th>long-term_memorability</th>\n",
              "      <th>nb_long-term_annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6000.000000</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>6000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.860243</td>\n",
              "      <td>36.291500</td>\n",
              "      <td>0.778942</td>\n",
              "      <td>12.764667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.080655</td>\n",
              "      <td>8.356285</td>\n",
              "      <td>0.144692</td>\n",
              "      <td>3.544815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.388000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.811000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.867000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.923000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.989000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a74ff3f8-9f1c-45ac-bc18-006bb68be070')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a74ff3f8-9f1c-45ac-bc18-006bb68be070 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a74ff3f8-9f1c-45ac-bc18-006bb68be070');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZFZFaCm25Pl"
      },
      "source": [
        "### c. Functions to read the selected features\n",
        "Those functions were provided for the assignment. They will parse some of the provided files to extract the data related to the videos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6f685cJ2sA8"
      },
      "source": [
        "# data analysis packages\n",
        "import pandas as pd # We put it again as the first import could not be always executed.\n",
        "import numpy as np\n",
        "\n",
        "def read_C3D(fname):\n",
        "    \"\"\"Scan vectors from file\"\"\"\n",
        "    with open(fname) as f:\n",
        "        for line in f:\n",
        "            C3D =[float(item) for item in line.split()] # convert to float type, using default separator\n",
        "    return C3D\n",
        "\n",
        "def read_HMP(fname):\n",
        "    \"\"\"Scan HMP(Histogram of Motion Patterns) features from file\"\"\"\n",
        "    with open(fname) as f:\n",
        "        for line in f:\n",
        "            pairs=line.split()\n",
        "            HMP_temp = { int(p.split(':')[0]) : float(p.split(':')[1]) for p in pairs}\n",
        "    # there are 6075 bins, fill zeros\n",
        "    HMP = np.zeros(6075)\n",
        "    for idx in HMP_temp.keys():\n",
        "        HMP[idx-1] = HMP_temp[idx]\n",
        "    return HMP\n",
        "\n",
        "def read_caps(fname):\n",
        "    \"\"\"Load the captions into a dataframe\"\"\"\n",
        "    vn = []\n",
        "    cap = []\n",
        "    df = pd.DataFrame();\n",
        "    with open(fname) as f:\n",
        "        for line in f:\n",
        "            pairs = line.split()\n",
        "            vn.append(pairs[0])\n",
        "            cap.append(pairs[1])\n",
        "        df['video']=vn\n",
        "        df['caption']=cap\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAqV760CgMMD"
      },
      "source": [
        "### d. Spearman Score\n",
        "This function, provided for the assignment and modified to return the results, will determine the Spearman score for short-term and long-term memorability, based on the result of the neural network and a ground truth.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj9MinTxgQgK"
      },
      "source": [
        "def Get_score(Y_pred,Y_true):\n",
        "    '''Calculate the Spearmann\"s correlation coefficient'''\n",
        "    result = []\n",
        "    Y_pred = np.squeeze(Y_pred)\n",
        "    Y_true = np.squeeze(Y_true)\n",
        "    if Y_pred.shape != Y_true.shape:\n",
        "        print('Input shapes don\\'t match!')\n",
        "    else:\n",
        "        if len(Y_pred.shape) == 1:\n",
        "            Res = pd.DataFrame({'Y_true':Y_true,'Y_pred':Y_pred})\n",
        "            score_mat = Res[['Y_true','Y_pred']].corr(method='spearman',min_periods=1)\n",
        "            print('The Spearman\\'s correlation coefficient is: %.3f' % score_mat.iloc[1][0])\n",
        "            return '%.3f' % score_mat.iloc[1][0]\n",
        "        else:\n",
        "            for ii in range(Y_pred.shape[1]):\n",
        "                temp = Get_score(Y_pred[:,ii],Y_true[:,ii])\n",
        "                if (temp != None):\n",
        "                  result.append(temp)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLHfz7A79ua0"
      },
      "source": [
        "# 2. CAP Feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGXawp4qguMp"
      },
      "source": [
        "### a. Load the feature's data\n",
        "This feature has all its data in a single file. We extract the text caption from here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCRBiv5igySx"
      },
      "source": [
        "df_cap=read_caps('Captions/dev-set_video-captions.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohsp6iDOhorR"
      },
      "source": [
        "We then remove the English stop words with the nltk (Natural Language ToolKit) library and the punctuation with the string library.\n",
        "\n",
        "We create a counter that we are going to use later with the Keras Tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRUAw4AKhoYz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0b56c799-f417-435f-e1ff-962b43b4e48c"
      },
      "source": [
        "\"\"\"remove ponctuation and stop words from the captions and initialize the Counter (to give a word a number thanks to its position)\"\"\"\n",
        "\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "\n",
        "%pip install nltk\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "common_words = set(stopwords.words('english'))\n",
        "\n",
        "counts = Counter()\n",
        "\n",
        "for i, cap in enumerate(df_cap['caption']):\n",
        "    # replace punctuations with space\n",
        "    # convert words to lower case\n",
        "    text = ''.join([c if c not in punctuation else ' ' for c in cap]).lower()\n",
        "\n",
        "    #remove common words\n",
        "    querywords = text.split()\n",
        "    text = ' '.join([word for word in querywords if word not in common_words]).lower()\n",
        "\n",
        "    counts.update(text.split())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az0FOGN9hN6r"
      },
      "source": [
        "We remove the words that are present only once in the counter, as we cannot find any correlation between them and the short-term and long-term memorability. Futhermore, it reduces the risk of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KkTrwGShML9"
      },
      "source": [
        "counts_captions = Counter({k: counts for k, counts in counts.items() if counts >= 2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJe4KNdFiWRG"
      },
      "source": [
        "We use a tokenizer to convert the words in the counter into integers, and we use the method 'fit_on_texts' to constitute an internal dictionary. This is required before using the method \"texts_to_matrix\".\n",
        "\n",
        "This method will allow us to transform our data to an [one-hot-res matrix](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f), which provide better performance (see in Results - Optimizing the datas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf5FwztrptaX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fef7cb9b-06e7-41e9-fc32-a8111d92b1b1"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=len(counts_captions))\n",
        "\n",
        "#Updates internal vocabulary based on a list of texts.\n",
        "tokenizer.fit_on_texts(list(counts_captions)) #turning each text into either a sequence of integers (for the transformation of the data for the one-hot encoding)\n",
        "\n",
        "#Convert a list of texts to a Numpy matrix.\n",
        "one_hot_res_captions = tokenizer.texts_to_matrix(list(df_cap.caption.values),mode='binary') #one-hot encoding (creating a matrix optimized for training)\n",
        "\n",
        "#We don't need sequences if we use one_hot_res\n",
        "#sequences = tokenizer.texts_to_sequences(list(df_cap.caption.values)) #location of words for each captions\n",
        "\n",
        "one_hot_res_captions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 3020)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUE8M8dYDhrS"
      },
      "source": [
        "### b. Define the model\n",
        "Here we define the model used for the Caption Feature. We use different regularizers to avoid over-fitting.\n",
        "\n",
        "We use one layer with a number of nodes related to the size of the input (3020/10 => 302). See 6.Results to see how we ended up with this architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON9sdn0wDkhq"
      },
      "source": [
        "def CAPModel():\n",
        "  len_token = len(counts_captions)\n",
        "\n",
        "  inputX = Input(shape=(len_token,))\n",
        "  x = layers.Dense(int(len_token / 10), activation=\"relu\", bias_regularizer=regularizers.l2(0.001), activity_regularizer=regularizers.l2(0.001), kernel_regularizer=regularizers.l2(0.001))(inputX)\n",
        "  return Model(inputs=inputX, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk2D9IFLu-kS"
      },
      "source": [
        "#3. C3D Feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTy7FF5Uq_HS"
      },
      "source": [
        "### a. Load the feature's data\n",
        "To extract the data related to this feature, we need to parse one file per video. To do so, we use the video list generated while processing the Caption feature.\n",
        "\n",
        "This process can take a long time to finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Splt3DPYwKUM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ea8ef96525194d01b0f945b63c027509",
            "28dc5c105856418699b84a1d3ead4083",
            "4607880f82c847f2bf9387e357425547",
            "af0ee04ec38347759ed18946845e984f",
            "e7450412853a46a1b636a80dd71aeeaf",
            "a7213f46d84042368d256c77bbf9231f",
            "7f521120e6ed442b90700d5de1e2f6f3",
            "f84e1405a4604a7084fff8d3307aae27"
          ]
        },
        "outputId": "1b0adca2-10b7-4dc0-e9ac-5880a9e93365"
      },
      "source": [
        "from tqdm.notebook import tqdm #load bar\n",
        "\n",
        "def getC3D():\n",
        "  C3D = [] #Python list keep the order of assertion.\n",
        "  for video in tqdm(df_cap['video']):\n",
        "    fname = video.split('.')[0] + '.txt';\n",
        "    C3D.append(read_C3D('C3D/' + fname))\n",
        "  return C3D\n",
        "\n",
        "C3D = getC3D()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea8ef96525194d01b0f945b63c027509",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=6000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzl__gO2rszR"
      },
      "source": [
        "### b. Apply padding to the data\n",
        "We apply padding to be sure that the shape of the data extracted is homogeneous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPkvlWdkEZ2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9feb2a3-823c-4989-8634-97c865263c2d"
      },
      "source": [
        "#padding C3D\n",
        "\n",
        "C3D_len = max([len(i) for i in C3D])\n",
        "\n",
        "C3D_seq = np.zeros((len(C3D), C3D_len))\n",
        "for i in range(len(C3D)):\n",
        "    n = len(C3D[i])\n",
        "    if n==0:\n",
        "        print(i)\n",
        "    else:\n",
        "        C3D_seq[i,-n:] = C3D[i]\n",
        "C3D_seq.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf94ZvnEDoNQ"
      },
      "source": [
        "### c. Define the model\n",
        "Here we define the model used for the C3D Feature. We use different regularizers to avoid over-fitting.\n",
        "\n",
        "We use one layer with a number of nodes related to the size of the input (101/10 => 10). See 6.Results to see how we ended up with this architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJujtlvCGjW"
      },
      "source": [
        "def C3DModel():\n",
        "\n",
        "  inputX = Input(shape=(C3D_len,))\n",
        "  x = layers.Dense(int(C3D_len / 10), activation=\"relu\", bias_regularizer=regularizers.l2(0.001), activity_regularizer=regularizers.l2(0.001), kernel_regularizer=regularizers.l2(0.001))(inputX)\n",
        "  return Model(inputs=inputX, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "108cqSxAwCqH"
      },
      "source": [
        "#4. HMP Feature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySMFaLVas_Jq"
      },
      "source": [
        "### a. Load the feature's data\n",
        "As for C3D feature, to extract the data related to this feature, we need to parse one file per video. To do so, we use the video list generated while processing the Caption feature.\n",
        "\n",
        "This process can take a long time to finish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNbAvxzi1OPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "09395ec5c4104369b7f7f84e988e444e",
            "81078f9f709f4e5297ee7a65a29351e8",
            "939e3f059476476fa47a8d3fb8d3c715",
            "913e0e4242ef4765aab6558b63730f4a",
            "63f91a87b7844ce284a4018b2ba79bab",
            "960e45b7c78646f48c718863fa2c77b0",
            "cc181147871442ca86433b5010ea3d6d",
            "32e45549d20e43d98a0c289f7c508ba6"
          ]
        },
        "outputId": "d1120d99-9dec-48ea-a558-f97a61fc7091"
      },
      "source": [
        "def getHMP():\n",
        "  HMP = []\n",
        "  for video in tqdm(df_cap['video']):\n",
        "    fname = video.split('.')[0] + '.txt';\n",
        "    HMP.append(read_HMP('HMP/' + fname))\n",
        "  return HMP\n",
        "\n",
        "HMP = getHMP()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09395ec5c4104369b7f7f84e988e444e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=6000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C5oj-qztJCa"
      },
      "source": [
        "\n",
        "### b. Apply padding to the data\n",
        "We apply padding to be sure that the shape of the data extracted is homogeneous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POPBJYLVHODN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eb34015-326f-4b5c-e4fc-2b6b4fb756ba"
      },
      "source": [
        "#padding HMP\n",
        "\n",
        "HMP_len = max([len(i) for i in HMP])\n",
        "\n",
        "HMP_seq = np.zeros((len(HMP), HMP_len))\n",
        "for i in range(len(HMP)):\n",
        "    n = len(HMP[i])\n",
        "    if n==0:\n",
        "        print(i)\n",
        "    else:\n",
        "        HMP_seq[i,-n:] = HMP[i]\n",
        "HMP_seq.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 6075)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmvNzHt1HLGO"
      },
      "source": [
        "### c. Define the model\n",
        "Here we define the model used for the HMP Feature. We use different regularizers to avoid over-fitting.\n",
        "\n",
        "We use one layer with a number of nodes related to the size of the input (6075/10 => 607). See 6.Results to see how we ended up with this architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeRctIKrx95e"
      },
      "source": [
        "def HMPModel():\n",
        "\n",
        "  inputX = Input(shape=(HMP_len,))\n",
        "  x = layers.Dense(int(HMP_len / 10), activation=\"relu\", bias_regularizer=regularizers.l2(0.001), activity_regularizer=regularizers.l2(0.001), kernel_regularizer=regularizers.l2(0.001))(inputX)\n",
        "  return Model(inputs=inputX, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWD4qFlCnZtK"
      },
      "source": [
        "#5. Build Network and assemble features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToCL-6EJ_H1v"
      },
      "source": [
        "### a. Define the model\n",
        "Here we are defining the final model that we are gonna use for our predictions. This model combine and encapsulate the other models defined before. See 7.Result - Optimizing the model #2 for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea4sw9UH_9A3"
      },
      "source": [
        "from tensorflow.python.keras import Input\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import Model\n",
        "from tensorflow.python.keras import regularizers\n",
        "from tensorflow.python.keras import callbacks\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def finalModel(models):\n",
        "  inputs = [] # Python lists keep the order\n",
        "  outputs = []\n",
        "  for model in models:\n",
        "    inputs.append(model.input)\n",
        "    outputs.append(model.output)\n",
        "  combined = layers.concatenate(outputs)\n",
        "  #z = layers.Dense(len(outputs) * 2, activation=\"relu\", bias_regularizer=regularizers.l2(0.001), activity_regularizer=regularizers.l2(0.001), kernel_regularizer=regularizers.l2(0.001))(combined)\n",
        "  z = layers.Dense(2, activation=\"sigmoid\")(combined)\n",
        "  return Model(inputs=inputs, outputs=z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEr_mAzHASno"
      },
      "source": [
        "###b. Define the training and the test sets\n",
        "Here we are defining the two sets (train and test) that we need in order to feed our model, and to test it (See 1.d - Spearman Score).\n",
        "\n",
        "- X_train is the data that we are going to feed our network with\n",
        "- Y_train is the ground trust associated with the data in X_train\n",
        "- X_test is the data that we are going to test our network with\n",
        "- Y_test is the ground trust associated with the data in X_test\n",
        "\n",
        "We divide our video set so we have 4800 video to train on and 1200 video reserved for testing the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dj7i0bwB_mn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def getdata():\n",
        "  GT = ground_truth[['short-term_memorability','long-term_memorability']].values\n",
        "  CAP = one_hot_res_captions\n",
        "  C3D = C3D_seq\n",
        "  HMP = HMP_seq\n",
        "  CAP_train, CAP_test, C3D_train, C3D_test, HMP_train, HMP_test, GT_train, GT_test = train_test_split(CAP, C3D, HMP, GT, test_size=0.2, random_state=42) #random_state for reproductability\n",
        "\n",
        "  X_train = [CAP_train, C3D_train, HMP_train]\n",
        "  Y_train = GT_train\n",
        "  X_test = [CAP_test, C3D_test, HMP_test]\n",
        "  Y_test = GT_test\n",
        "  return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMcWiPIDCuBd"
      },
      "source": [
        "###c. Display the model history\n",
        "To detect over-fitting, we display some information about the accuracy and the loss over the epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auxb5byHCJc0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(history):\n",
        "  loss = history.history['loss']\n",
        "  epochs = range(1,len(loss)+1)\n",
        "\n",
        "  plt.figure() #loss plot\n",
        "  val_loss = history.history['val_loss']\n",
        "  plt.plot(epochs,loss,'bo',label='Training loss')\n",
        "  plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure() #accuracy plot\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Acc')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnaXXNNVHXEB"
      },
      "source": [
        "### d. Training the model\n",
        "\n",
        "Here we are defining a function to train the model. We save the model's weigth each time we train, so we can go back (in the case we trained the model too much) or continue where we stopped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA4-dhlvHmIE"
      },
      "source": [
        "def train(epochs_input, n):\n",
        "\n",
        "  # compile the model\n",
        "  model.compile(optimizer='rmsprop', loss='mse',metrics=['accuracy'])\n",
        "\n",
        "  # This callback will stop the training when there is no improvement in\n",
        "  # the validation loss for three consecutive epochs.\n",
        "  callback = callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "  # training the model\n",
        "  history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs_input, callbacks=[callback])\n",
        "\n",
        "  #display training history\n",
        "  plot_results(history)\n",
        "\n",
        "  test(f'my_model_{n}')\n",
        "\n",
        "  model.save(f'../models/my_model_{n}.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNcvqtl8IRcF"
      },
      "source": [
        "###e. Test the model\n",
        "We need to test the model to determine the predictions scores. Then we create a .csv file related to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7fbidguIcJk"
      },
      "source": [
        "#from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "import csv\n",
        "\n",
        "def test(model_name):\n",
        "  predictions = model.predict(X_test)\n",
        "  results = Get_score(predictions, Y_test) #See 1.d Spearman Score\n",
        "  with open(f'../models/{model_name}.csv', mode='w') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    csv_writer.writerow(['Memorability', 'Score'])\n",
        "    csv_writer.writerow(['Short-Term', results[0]])\n",
        "    csv_writer.writerow(['Long-Term', results[1]])\n",
        "#  plot_model(model, to_file=f'../models/{model_name}.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jprmmS4KpnG"
      },
      "source": [
        "###f. (Optional) Script to train the model\n",
        "This is the script we can use to train our model.\n",
        "It asks (by several inputs) the behaviour the user wishes to use.\n",
        "\n",
        "For a simpler script that only test a pre-chose model and generate the .csv file with the results, see g. Test the saved model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIfQ5IduNOXj"
      },
      "source": [
        "In this script:\n",
        "\n",
        "- First, the user can choose to load a model\n",
        "- Next, the user can type a number. 0 will test the model, 1 or more will train the model the choosen number of times. In that case, a saved model would be generated each times with a associated .csv file.\n",
        "- Finally, if the user chose to train the model, it will ask how many epochs to use per training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppwI53CcDJt4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "28630fc6-44db-496b-eee0-2f9f9def442e"
      },
      "source": [
        "X_train, Y_train, X_test, Y_test = getdata()\n",
        "model = finalModel([CAPModel(), C3DModel(), HMPModel()])\n",
        "\n",
        "n = int(input(\"number of the model to load (see MyDrive/models for a list - -1 for no model)\\n\"))\n",
        "if (n >= 0):\n",
        "  model.load_weights(f'../models/my_model_{n}.h5')\n",
        "print(\"\")\n",
        "\n",
        "action = int(input(\"choose an action:\\n0 => test the model - n => train the model n times\\n\"))\n",
        "print(\"\")\n",
        "if (action <= 0):\n",
        "  test(f'my_model_{n}')\n",
        "else:\n",
        "  epochs_input = int(input(\"number of epochs (>=10 && <=500)\\n\"))\n",
        "  print(\"\")\n",
        "  if (epochs_input < 10):\n",
        "    epochs_input = 10\n",
        "  elif (epochs_input > 500):\n",
        "    epochs_input = 500\n",
        "  for i in range(0, action):\n",
        "    n += 1\n",
        "    train(epochs_input, n)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of the model to load (see MyDrive/models for a list - -1 for no model)\n",
            "22\n",
            "\n",
            "choose an action:\n",
            "0 => test the model - n => train the model n times\n",
            "0\n",
            "\n",
            "The Spearman's correlation coefficient is: 0.448\n",
            "The Spearman's correlation coefficient is: 0.200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Op-R-lENbLN"
      },
      "source": [
        "###g. Test the saved model\n",
        "This script is the same as f. Script to train the model, but it doesn't require the user input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeDV4Fk_OFaz"
      },
      "source": [
        "Instead, the following action are chose:\n",
        "- load the 'my_saved_model.h5' model\n",
        "- test it\n",
        "\n",
        "The 'my_saved_model.h5' file stores the weights that performed the best predictions compared to the other generated models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psk_f52sOY57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "310614cd-cec6-4759-cc3e-6af808bd44f2"
      },
      "source": [
        "X_train, Y_train, X_test, Y_test = getdata()\n",
        "model = finalModel([CAPModel(), C3DModel(), HMPModel()])\n",
        "\n",
        "model.load_weights(f'../models/my_saved_model.h5')\n",
        "test('my_saved_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Spearman's correlation coefficient is: 0.445\n",
            "The Spearman's correlation coefficient is: 0.206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBHUEc6Bx4la"
      },
      "source": [
        "#6. Results\n",
        "\n",
        "This part reports the several steps I took to complete this assigment.\n",
        "\n",
        "## The first model\n",
        "The first model I tried was the one provided as an example. It uses the captions feature.\n",
        "\n",
        "After comparing the efficiency with and without \"one-hot-res\", I chose to transform my data (captions)  in a \"one-hot-res\" matrix that led the model to offer better performances on the predictions.\n",
        "\n",
        "## Choosing the features\n",
        "\n",
        "I chose to implement 3 features based on the results of Rohit Gupta and Kush Motwani[[1]](http://ceur-ws.org/Vol-2283/MediaEval_18_paper_31.pdf) during the 2018 Media Eval Competition on the same subject. They got better results on, from the best performance: Captions, C3D, HMP, LBP.\n",
        "\n",
        "I chose to use only the first three because their implementations were provided. In opposition, whereas the Color Histogram implementation was provided, I chose to not use it because of the weak performance it achieved.\n",
        "\n",
        "## Choosing a model\n",
        "\n",
        "Because the first model was designed to treat only one feature, I had to change it.\n",
        "\n",
        "I followed the method explained in this [tutorial](https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/). I created three models (one for each feature) to avoid the mixing of different input data so I can have more flexibility by being able to choose different architetures for each network. Then I joined the inputs and outputs in a final model. This resulted in three sub-network in a single network.\n",
        "\n",
        "- CAP-model, C3D-model and HMP-model describe the three features models.\n",
        "- Final-model describes the model where the other models are joined, producing the output.\n",
        "\n",
        "Then I used the provided implementations of the differents features (Captions, C3D, HMP) to extract the data concerning the videos and I fed the model with it.\n",
        "\n",
        "## Optimizing the model #1\n",
        "\n",
        "I first tried several architectures before choosing one.\n",
        "\n",
        "The first architectures I tried were working on this model:\n",
        "\n",
        "- CAP-model, C3D-model and HMP-model had an input layer, then 3 layers with each n\\*4 nodes, n\\*2 nodes and n nodes, n being generally 8.\n",
        "\n",
        "- Final-model had two layers, one with (number of features-model \\*2) nodes and the second with 2 nodes, the output layer.\n",
        "\n",
        "## Optimizing the datas\n",
        "\n",
        "Like Rohit Gupta and Kush Motwani[[1]](http://ceur-ws.org/Vol-2283/MediaEval_18_paper_31.pdf), I chose to remove English stop-words from the captions while generating data for the Captions feature. I also chose to remove the words that were mentioned only once, to remove the less used words that the model would have not learned a pattern on.\n",
        "\n",
        "The performance improved drastically, multiplying per two the predictions accuracy.\n",
        "\n",
        "## Optimizing the model #2\n",
        "\n",
        "After conducting some research on the Internet, I figured out that [\"One hidden layer is sufficient for the large majority of problems\"](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw).\n",
        "\n",
        "For the number of nodes per layers, I chose, based on the same recommendations, to use (lenght of the inputed data / 2) nodes for CAP-model, C3D-model and HMP-model.\n",
        "\n",
        "The architecure was then working on this model:\n",
        "- an input layer, then one layers with (lenght of the inputed data / 2) nodes for CAP-model, C3D-model and HMP-model.\n",
        "- Final-model was only composed of the output layer (2 nodes)\n",
        "\n",
        "This architecture was taking a long time to train and was offerfitting really quickly (less than ten epochs)\n",
        "\n",
        "I decided to used the three types of [regularizer Keras offer](https://keras.io/regularizers/) to fix the issue of overfitting. The performance of the network improved.\n",
        "\n",
        "<br/>\n",
        "\n",
        "I then decided to reduce per five the size of the layers on the features-model. In fact, the combined inputs represent a length of 9196. If we divide the length of each input per two, it give 4597 neurones, which was a lot for this task. After reducing the size of the layer, the model finally have 919 neurones.\n",
        "\n",
        "Because of a performance improvment on the prediction, I used this architecture, which worked on this model:\n",
        "- an input layern, then one layers with (lenght of the inputed data / 10) nodes for CAP-model, C3D-model and HMP-model.\n",
        "- Final-model was only composed of the output layer (2 nodes)\n"
      ]
    }
  ]
}